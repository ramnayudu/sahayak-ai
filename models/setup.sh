#!/bin/bash

# Sahayak AI - Ollama Model Setup Script
# This script sets up the local AI models for offline mode

echo "ğŸš€ Setting up Sahayak AI Offline Models..."

# Check if Ollama is installed
if ! command -v ollama &> /dev/null; then
    echo "ğŸ“¦ Installing Ollama..."
    curl -fsSL https://ollama.ai/install.sh | sh
    
    # Start Ollama service
    echo "ğŸ”§ Starting Ollama service..."
    ollama serve &
    sleep 5
else
    echo "âœ… Ollama is already installed"
fi

# Pull required models
echo "â¬‡ï¸ Downloading Gemma models for offline use..."

# Gemma 2B - Faster, good for basic tasks
echo "ğŸ“¥ Pulling Gemma 2B (quantized)..."
ollama pull gemma:2b

# Gemma 7B - Better quality, slower
echo "ğŸ“¥ Pulling Gemma 7B (quantized)..."
ollama pull gemma:7b

# Optional: Pull other useful models
# echo "ğŸ“¥ Pulling additional models..."
# ollama pull llama2:7b
# ollama pull codellama:7b

echo "ğŸ‰ Model setup complete!"

# Test the models
echo "ğŸ§ª Testing models..."

echo "Testing Gemma 2B:"
ollama run gemma:2b "Hello, I am a teacher. Can you help me create a simple math lesson?"

echo ""
echo "Testing Gemma 7B:"
ollama run gemma:7b "Create a brief science lesson plan for grade 3 students about plants."

echo ""
echo "âœ… All models are ready for use!"
echo ""
echo "ğŸ“‹ Available models:"
ollama list

echo ""
echo "ğŸ’¡ Usage:"
echo "- Start Ollama: ollama serve"
echo "- Use Gemma 2B: ollama run gemma:2b"
echo "- Use Gemma 7B: ollama run gemma:7b"
echo "- API endpoint: http://localhost:11434"
